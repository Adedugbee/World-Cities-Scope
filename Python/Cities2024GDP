import requests
from bs4 import BeautifulSoup
import pandas as pd
import numpy as np

url = "https://en.wikipedia.org/wiki/List_of_cities_by_GDP"

# Send HTTP request and parse the page
response = requests.get(url)
soup = BeautifulSoup(response.content, "html.parser")

# Find the first table with class "wikitable"
table = soup.find("table", {"class": "wikitable"})

if table:
    rows = table.find_all("tr")
    data = []

    for row in rows[1:]:  # Skip header
        cols = row.find_all(["td", "th"])  # Handle any mixed header cells
        col_text = [col.get_text(strip=True) for col in cols]

        # Print col_text to debug (optional)
        # print(col_text)

        # Only process rows with enough columns
        if len(col_text) >= 4:
            city = col_text[1]
            country = col_text[2]
            gdp_raw = col_text[3].replace(",", "").replace("$", "")

            try:
                gdp = float(gdp_raw)
            except ValueError:
                gdp = np.nan

            data.append([city, country, gdp])

    # Create DataFrame
    df = pd.DataFrame(data, columns=["City", "Country", "GDP in Millions USD"])
    print(df.head(5))

    # Optional: Save to CSV
    # df.to_csv("Cities-GDP.csv", index=False)
else:
    print("GDP table not found.")
