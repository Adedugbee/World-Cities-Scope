# Import necessary packages
import requests
from bs4 import BeautifulSoup
import pandas as pd
import numpy as np

url = "https://en.wikipedia.org/wiki/List_of_cities_by_GDP"

# Send HTTP request and parse the page
response = requests.get(url)
soup = BeautifulSoup(response.content, "html.parser")

# Locate the correct table by class name
table = soup.find("table", {"class": "wikitable"})

# Safety check if table exists
if table:
    rows = table.find_all("tr")
    data = []

    for row in rows[1:]:  # Skip the header row
        cols = row.find_all("td")

        # Make sure there are at least 4 columns
        if len(cols) >= 4:
            city = cols[1].text.strip()
            country = cols[2].text.strip()
            gdp = cols[3].text.strip().replace(",", "").replace("$", "")

            try:
                gdp = float(gdp)
            except ValueError:
                gdp = np.nan

            data.append([city, country, gdp])

    # Create DataFrame
    df = pd.DataFrame(data, columns=["City", "Country", "GDP in Millions USD"])
    print(df.head(5))

    # Save to CSV if needed
    # df.to_csv("Cities-GDP.csv", index=False)
else:
    print("GDP table not found on the page.")
